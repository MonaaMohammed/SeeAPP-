{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of tryCap301.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MonaaMohammed/SeeAPP-/blob/master/Copy_of_tryCap301.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVUyP5qoJbJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/pjreddie/darknet\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQWrzGHde6Gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd darknet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-RQI1LdRonv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls\n",
        "!sed -i 's/GPU=0/GPU=1/g' Makefile\n",
        "!make\n",
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huTRGaZYfDVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd '/content'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTepnTDGJUih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#/////////////////////////////////////////// Constructing Cell //////////////////////////////////////////////////////////////\n",
        "#-------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "!pip install opencv-python  \n",
        "!pip list\n",
        "!pip install pydub\n",
        "!pip install gtts \n",
        "\n",
        "#-------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "from six.moves import SimpleHTTPServer\n",
        "from six.moves import socketserver\n",
        "from google.colab import output\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from gtts import gTTS\n",
        "from google.colab import files\n",
        "\n",
        "#-------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import imutils\n",
        "import subprocess\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import random    \n",
        "import socket\n",
        "import threading\n",
        "import IPython\n",
        "import portpicker\n",
        "\n",
        "#-------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# load the COCO class labels our YOLO model was trained on\n",
        "LABELS = open(\"/content/darknet/data/coco.names\").read().strip().split(\"\\n\")\n",
        "\n",
        "# load our YOLO object detector trained on COCO dataset (80 classes)\n",
        "print(\"[INFO] loading YOLO from disk...\")\n",
        "net = cv2.dnn.readNetFromDarknet(\"/content/darknet/cfg/yolov3.cfg\", \"/content/darknet/yolov3.weights\")\n",
        "\n",
        "# determine only the *output* layer names that we need from YOLO\n",
        "ln = net.getLayerNames()\n",
        "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "#-------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#Using the capture snippet and modify it to take a capture automatically\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "      \n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename\n",
        "\n",
        "#-------------------------------------------------------------------------------------------------------------------------------\n",
        "#Selection of objects (Currently three objects)\n",
        "def mostDangerousClass(setOfClasses):\n",
        "    sub = \"car\"\n",
        "    res = [s for s in setOfClasses if sub in s]\n",
        "    if not res:\n",
        "        sub = \"person\"\n",
        "        res = [s for s in setOfClasses if sub in s]\n",
        "        if not res:\n",
        "            sub = \"chair\"\n",
        "            res = [s for s in setOfClasses if sub in s]\n",
        "    return res \n",
        "    \n",
        "def mostDangerousSide(leftSide, rightSide):\n",
        "    sides = []\n",
        "    sides.append(leftSide)\n",
        "    sides.append(rightSide)\n",
        "    return mostDangerousClass(sides)\n",
        "#--------------------------------------------------------------------------------------------------------------------------------\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "psqZZeB8B7dv",
        "colab": {}
      },
      "source": [
        "#////////////////////////////////////////////////////Start of the process/////////////////////////////////////////////////////////\n",
        "#----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "#Looping in order to run the cell one time\n",
        "while True:\n",
        "\n",
        "  #First: Capturing an Image\n",
        "  #----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "  try:\n",
        "    filename = take_photo()\n",
        "  except Exception as err:\n",
        "    # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "    # grant the page permission to access it.\n",
        "    print(str(err))\n",
        "\n",
        "\n",
        "  #----------------------------------------------------------------------------------------------------------------------\n",
        "  #Second: Use YOLO to analyze the image\n",
        "  #----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "  imageSource = '/content/'+filename\n",
        "\n",
        "  img = cv2.imread(imageSource)\n",
        "  COLORS = np.random.randint(0, 255, size=(len(LABELS), 3),dtype=\"uint8\")\n",
        "\n",
        "  # grab the image dimensions and convert it to a blob\n",
        "  (H, W) = img.shape[:2]\n",
        "  # construct a blob from the input image and then perform a forward\n",
        "  # pass of the YOLO object detector, giving us our bounding boxes and\n",
        "  # associated probabilities\n",
        "  blob = cv2.dnn.blobFromImage(img, 1 / 255.0, (416, 416),\n",
        "  swapRB=True, crop=False)\n",
        "  net.setInput(blob)\n",
        "  layerOutputs = net.forward(ln)\n",
        "\n",
        "  # initialize our lists of detected bounding boxes, confidences, and\n",
        "  # class IDs, respectively\n",
        "  boxes = []\n",
        "  confidences = []\n",
        "  classIDs = []\n",
        "  centers = []\n",
        "  detected= []\n",
        "\n",
        "\n",
        "  #--------------------------------------------------------------------------------------------------  \n",
        "  minPer = {0:3.1, 2:6.2, 56:2.1}\n",
        "  maxPer = {0:12.1, 2:24.2, 56:4.2}\n",
        "  spacePers = []\n",
        "\n",
        "  ourClassesIDs = [0, 2, 56]\n",
        "\n",
        "  wrnCenter = set()\n",
        "  wrnLeft = set()\n",
        "  wrnRight = set()\n",
        "\n",
        "  infCenter = set()\n",
        "  infLeft = set()\n",
        "  infRight = set()\n",
        "  #--------------------------------------------------------------------------------------------------\n",
        "\n",
        "  # loop over each of the layer outputs\n",
        "  for output in layerOutputs:\n",
        "\n",
        "    # loop over each of the detections\n",
        "    for detection in output:\n",
        "\n",
        "        # extract the class ID and confidence (i.e., probability) of\n",
        "        # the current object detection\n",
        "        scores = detection[5:]\n",
        "        classID = np.argmax(scores)\n",
        "        confidence = scores[classID]\n",
        "\n",
        "        # filter out weak predictions by ensuring the detected\n",
        "        # probability is greater than the minimum probability\n",
        "        #and filter out classes we haven't measure yet    \n",
        "        if confidence > 0.5 and classID in ourClassesIDs:\n",
        "\n",
        "            # scale the bounding box coordinates back relative to the\n",
        "            # size of the image, keeping in mind that YOLO actually\n",
        "            # returns the center (x, y)-coordinates of the bounding\n",
        "            # box followed by the boxes' width and height\n",
        "            box = detection[0:4] * np.array([W, H, W, H])\n",
        "            (centerX, centerY, width, height) = box.astype(\"int\")\n",
        "\n",
        "            #filter out far objects \n",
        "            spacePer = (width * height)/(img.shape[0] * img.shape[1]) * 100  \n",
        "            spacePers.append(spacePer)\n",
        "            if spacePer < minPer[classID]: \n",
        "              continue\n",
        "\n",
        "            # use the center (x, y)-coordinates to derive the top and\n",
        "            # and left corner of the bounding box\n",
        "            x = int(centerX - (width / 2))\n",
        "            y = int(centerY - (height / 2))\n",
        "\n",
        "            # update our list of bounding box coordinates, confidences,\n",
        "            # and class IDs\n",
        "            boxes.append([x, y, int(width), int(height)])\n",
        "            confidences.append(float(confidence))\n",
        "            classIDs.append(classID)\n",
        "            centers.append((centerX, centerY))\n",
        "  #--------------------------------------------------------------------------------------------------          \n",
        "\n",
        "  # apply non-maxima suppression to suppress weak, overlapping\n",
        "  # bounding boxes\n",
        "  idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.3)\n",
        "\n",
        "  texts = []\n",
        "\n",
        "  # ensure at least one detection exists\n",
        "  if len(idxs) > 0:\n",
        "\n",
        "    # loop over the indexes we are keeping\n",
        "    for i in idxs.flatten():\n",
        "\n",
        "      # extract the bounding box coordinates\n",
        "      (x, y) = (boxes[i][0], boxes[i][1])\n",
        "      (w, h) = (boxes[i][2], boxes[i][3])\n",
        "\n",
        "      # draw a bounding box rectangle and label on the frame\n",
        "      color = [int(c) for c in COLORS[classIDs[i]]]\n",
        "      cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "      text = \"{}: {:.4f}\".format(LABELS[classIDs[i]],\n",
        "        confidences[i])\n",
        "      cv2.putText(img, text, (x, y - 5),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "      label = LABELS[classIDs[i]]\n",
        "      if label not in detected:\n",
        "        # find positions and areas of the classes--> (Warning, Informing Areas)\n",
        "        centerX, centerY = centers[i][0], centers[i][1]\n",
        "\n",
        "        if centerX <= W/3:\n",
        "          W_pos = \"left \"\n",
        "          if spacePers[i] <= maxPer[classIDs[i]] and spacePers[i] >= minPer[classIDs[i]]:\n",
        "            infLeft.add(W_pos + label)\n",
        "          else:\n",
        "            wrnLeft.add(W_pos + label)\n",
        "        elif centerX <= (W/3 * 2):\n",
        "          W_pos = \"center \"\n",
        "          if spacePers[i] <= maxPer[classIDs[i]] and spacePers[i] >= minPer[classIDs[i]]:\n",
        "            infCenter.add(W_pos + label)\n",
        "          else:\n",
        "            wrnCenter.add(W_pos + label)\n",
        "        else:\n",
        "          W_pos = \"right \"\n",
        "          if spacePers[i] <= maxPer[classIDs[i]] and spacePers[i] >= minPer[classIDs[i]]:\n",
        "            infRight.add(W_pos + label)\n",
        "          else:\n",
        "            wrnRight.add(W_pos + label)  \n",
        "\n",
        "        detected.append(label)\n",
        "\n",
        "\n",
        "  #obtaining the texts based on:\n",
        "  #(i)- the most dangerous classes on each location\n",
        "  #(ii)- the area of the object (Warning Area or Informing Area):\n",
        "  if wrnCenter or wrnLeft or wrnRight:\n",
        "    #Warning Area\n",
        "    if wrnCenter:\n",
        "      texts.append(mostDangerousClass(wrnCenter))\n",
        "    if wrnLeft or wrnRight:\n",
        "      texts.append(mostDangerousSide(mostDangerousClass(wrnLeft), mostDangerousClass(wrnRight)))\n",
        "  else:\n",
        "    #Informing Area \n",
        "    if infCenter:\n",
        "      texts.append(mostDangerousClass(infCenter))\n",
        "    if wrnLeft or wrnRight:\n",
        "      texts.append(mostDangerousSide(mostDangerousClass(infLeft), mostDangerousClass(infRight)))\n",
        "\n",
        "\n",
        "  #----------------------------------------------------------------------------------------------------------------------\n",
        "  #Third: Convert the text output to speech\n",
        "  #----------------------------------------------------------------------------------------------------------------------\n",
        "  if not texts:\n",
        "    texts.append(\"Nothing\")\n",
        "  tts = gTTS(text=str(texts) , lang='en')\n",
        "  tts.save(\"ttsFile.mp3\")  \n",
        " \n",
        "  #----------------------------------------------------------------------------------------------------------------------\n",
        "  #Using multithreading function in order to run the Audio in a loop\n",
        "  #----------------------------------------------------------------------------------------------------------------------\n",
        "  from six.moves import SimpleHTTPServer\n",
        "  from six.moves import socketserver\n",
        "  from google.colab import output\n",
        "  #----------------------------------------------------------------------------------------------------------------------\n",
        "  class _V6Server(socketserver.TCPServer):\n",
        "\n",
        "    address_family = socket.AF_INET6\n",
        "\n",
        "  class _FileHandler(SimpleHTTPServer.SimpleHTTPRequestHandler):\n",
        "    \"\"\"SimpleHTTPRequestHandler with a couple tweaks.\"\"\"\n",
        "\n",
        "    def translate_path(self, path):\n",
        "      # Client specifies absolute paths.\n",
        "      return path\n",
        "\n",
        "    def log_message(self, fmt, *args):\n",
        "      # Suppress logging since it's on the background. Any errors will be reported\n",
        "      # via the handler.\n",
        "      pass\n",
        "\n",
        "    def end_headers(self):\n",
        "      # Do not cache the response in the notebook, since it may be quite large.\n",
        "      self.send_header('x-colab-notebook-cache-control', 'no-cache')\n",
        "      SimpleHTTPServer.SimpleHTTPRequestHandler.end_headers(self)\n",
        "\n",
        "\n",
        "  def play_audio(filename):\n",
        "    \"\"\"Downloads the file to the user's local disk via a browser download action.\n",
        "\n",
        "    Args:\n",
        "      filename: Name of the file on disk to be downloaded.\n",
        "    \"\"\"\n",
        "\n",
        "    started = threading.Event()\n",
        "    port = portpicker.pick_unused_port()\n",
        "\n",
        "    def server_entry():\n",
        "      httpd = _V6Server(('::', port), _FileHandler)\n",
        "      started.set()\n",
        "      # Serve multiple requests, in case the audio is played more than once.\n",
        "      httpd.serve_forever()\n",
        "\n",
        "    thread = threading.Thread(target=server_entry)\n",
        "    thread.start()\n",
        "    started.wait()\n",
        "\n",
        "    output.eval_js(\"\"\"\n",
        "      (()=> {\n",
        "        const audio = document.createElement('audio');\n",
        "        audio.controls = true;\n",
        "        audio.autoplay = true;\n",
        "        audio.src = `https://localhost:%(port)d%(path)s`;\n",
        "        document.body.appendChild(audio);\n",
        "      })()\n",
        "    \"\"\"% {'port': port, 'path': os.path.abspath(filename)})\n",
        "  #----------------------------------------------------------------------------------------------------------------------\n",
        "  play_audio(\"/content/ttsFile.mp3\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}